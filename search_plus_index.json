{"./":{"url":"./","title":"Introduction","keywords":"","body":" AVA Handbook AVA 是七牛云 AI 深度学习平台, 为深度学习提供一整套端到端解决方案, 包括数据管理, 镜像管理, 训练框架管理, 训练任务管理, 模型管理等. 通过 AVA 平台, 用户可以快速执行完整的深度学习流程, 包括导入训练数据, 方便地使用常用深度学习框架, 一键启动深度学习任务, 快速导出训练模型等. 整个操作过程都在 Portal 界面上进行, 并对深度训练使用者屏蔽具体实现细节, 使之可聚焦在解决问题本身. "},"01-introduction.html":{"url":"01-introduction.html","title":"1 概述","keywords":"","body":"概述 AVA 是七牛云的 AI 深度学习平台, 为深度训练提供一整套端到端的解决方案, 包括数据管理, 镜像管理, 训练框架管理, 训练任务管理, 模型管理等. 通过 AVA 平台, 用户可以快速的执行完整的深度训练流程, 包括导入训练数据, 方便的使用常用的深度学习框架, 一键启动深度训练任务, 快速导出训练模型等. 整个操作过程都在 Portal 界面上进行, 并对深度训练使用者屏蔽具体实现细节, 使之可聚焦在解决问题本身上. AVA 平台面向的用户主要有如下几类: 算法工程师 这也是平台最初的设计目标. 算法工程师日常打交道最多的工具或资源有: 容器, 存储, CPU, GPU, 训练框架, 训练算法, 训练数据等. 对于算法工程师来说, AVA平台做好最基本的资源管理, 使其能高效地使用这些资源, 并比较好地结合算法设计本身在平台上开展测试和调整算法参数. 深度学习相关业务使用人员, 包括新入门的深度学习学习者和使用者 这一类用户对算法和具体训练过程有一定的了解, 能用算法解决一类问题, 但是, 无法深入定制算法, 调整算法参数以及做深度的性能优化. 对这一类用户来说, AVA平台提供了一个简易的执行操作平台, 让他们可以一键启动深度训练, 快速得到训练结果. 平台管理人员 AVA 平台是对资源管理的一个抽象, 其中包括存储资源, 计算资源, 镜像 (容器) 资源, 网络资源, 算法框架等. 管理人员通过AVA平台可以迅速掌握系统中资源的使用情况, 判断系统资源是否匮乏或者存在瓶颈, 并能控制不同使用者使用资源的比例和方式. AVA平台设计的目的是, 使所有与深度学习和训练相关的操作都可以在AVA平台完成, 包括如下方面: 存储资源的管理 众所周知, 深度训练需要的数据是海量的, 并且大部分的数据都来源于互联网, 存放于互联网. AVA平台适应数据存取这一特性, 通过对接七牛云对象存储 (KODO) , 实现所有数据管理和落地都在云端. 同时, 拥有管理和对接其他云存储服务的能力, 比如 AWS S3, 阿里 OSS 等. 在 AVA 平台可直接对云上 PB 级别的数据进行增删改查操作. 数据集管理 数据集是一类特殊存储的资料集合, 简而言之, 就是训练框架比如 MXNet 等需要的特定格式的存储类型集合. 一般的存储资源, 指的是具体的图片、视频等. 而训练框架为了性能考虑, 往往要把数据打包成特定的格式, 这就是数据集. AVA 平台可以从互联网上把指定的图片、视频或其他数据拉取到本地或七牛对象存储中, 并生成固定的格式供训练框架使用. GPU 管理 GPU 是最重要的计算资源, 其并行计算速度远远超过 CPU. 但其价格也远超 CPU, 在实际机房部署中, 相对 CPU, 量还是很少, 对深度训练使用者来说, CPU 相对富足, GPU 是稀缺资源. AVA 平台的一个主要任务是有效管理 GPU 资源, 通过合理划分和调度, 充分利用 GPU 资源, 使效能最大化. 同时, AVA 做的最重要的一件事情, 是实现存储和计算分离, 使得各自可以独立平行扩展. 深度学习框架管理 主要是通过容器镜像来实现的. 目前主流的深度学习框架 AVA 平台都提供支持, 包括 MXNet, Caffe, PyTorch 和 TensorFlow. 容器镜像管理 除了 AVA 平台提供的公有镜像外, 用户可以定制自己的镜像, 以后进行深度训练时使用自己定制的镜像. 训练过程管理 包括启动训练, 观察训练产生的模型, 进度, 还有终止训练. 这些操作都可以通过 Portal 完成. 分布式训练支持和调度管理 这是高阶功能. 通过分布式调度, AVA 可以利用多台机器的 GPU 执行训练, 加速深度训练. "},"02-register.html":{"url":"02-register.html","title":"2 AVA 申请注册流程","keywords":"","body":"AVA 申请注册流程 在开始使用深度学习平台之前，您首先需要完成下面2步。 1.注册七牛云Portal 1.1 账号注册 七牛云账号注册传送门 1.2 身份验证 注册之后默认为体验用户，免费额度有限，申请身份验证并通过之后，立刻获得10倍的免费额度。使用 AVA 深度学习平台必须完成身份验证，否则无法正常使用。 详细说明请查看认证说明文档。 体验用户： 标准用户： 2.申请开通深度学习平台AVA 请发送邮件到 atlab-review@qiniu.com，邮件中需要附上您的七牛账号及相关信息。如果您是七牛云人工智能团队的算法工程师，请注明您属于的是哪个组，如果是高校用户（老师或者学生），请填写申请表并附在邮件中。（申请表word下载链接） 邮件可参考以下题与格式： TO:atlab-review@qiniu.com Title:申请开通深度学习平台AVA－七牛云账号－算法工程师所在组（或高校老师学生所在的学校） 我的七牛云账号是： 我是七牛云人工智能团队的算法工程师视频组 或者 我是高校用户（老师或者学生）（并附上申请表）。 我们将在24小时内完成审核，审核通过后，我们会立即为您开通深度学习平台AVA。 3.登录深度学习平台AVA 3.1 登录平台 登录www.qiniu.com ，在资源主页找到深度学习平台，点击立即添加。 3.2 绑定存储空间 AVA平台会管理用户的数据集，并且在训练和推理的过程中，也会读取数据集中的数据进行训练和推理。所以，深度学习平台需要绑定您的数据集所在的存储空间。绑定成功后，平台中新产生的数据集、模型和训练产生的模型都会存储在绑定的存储空间。存储空间绑定后，不能修改，暂时只支持华东存储空间。 如果您还没有存储空间，那么这里的下拉菜单是空的，那您可以点击“新建存储空间”来新建一个新的空间。 3.3 加入群组 您现在已经可以登录深度学习平台AVA，并进行数据集预处理等操作，如需获取资源配额进行训练还需加入群组。加入群组您只需将平台绑定的存储空间名称发送邮件至 atlab-review@qiniu.com，我们会根据您的申请信息将您加入相关群组，加入后会发邮件通知。 成功开通深度学习平台AVA后，就可以登录七牛云portal，开始使用这个平台进行训练模型。 "},"03-concepts/3.1-dataset.html":{"url":"03-concepts/3.1-dataset.html","title":"3.1 数据集","keywords":"","body":"数据集 深度学习训练需要大量的数据, 一个训练需要的数据可以到达几十T的规模. 数据集的作用是以便利的方式给深度学习训练提供数据. 可以从两个角度理解数据集: 从狭义的角度, 数据集是深度学习训练框架需要的特定格式的输入数据, 比如格式化的 RecordIO, LMDB 等 从广义的角度, 数据集是所有提供给训练的数据, 包括互联网上的原图数据集, 上面所说的 RecordIO 格式数据, 还有存储在七牛或其他厂商的对象存储等 AVA 平台数据集管理对数据进行一定的处理后, 以标准文件系统的形式向深度学习训练提供输入, 包括原图格式和格式化的形式. 常见的处理提供数据集的方式有如下几种: 用户本存储在内部存储集群, 比如 CEPH 中的数据, AVA 可以把数据挂载到训练容器的文件系统中, 供训练直接使用 存储在七牛云对象存储或者其他厂商 (比如 AWS S3) 对象存储的数据, AVA提供转换协议, 训练可以文件系统协议访问对象存储 互联网上以 URL 标志的数据. 用户可以提供 JSON 文件, 其中每条记录是一个文件 URL, AVA 会将数据拉取下来, 并挂载到训练容器中 对一些框架需要的标准形式, AVA 可以把数据格式化为对应格式的文件, 供训练使用, 比如 RecordIO, LMDB 等 如果用户提供的数据带有标签, 则 AVA 除了把数据格式化为一定格式外, 还可以划分为训练集和验证机、测试集, 供训练使用 不同用户间的数据集还可以共享, 分为组内共享和全局共享 对于常用的训练数据, 比如 CIFAR, IMAGENET 等, AVA提供了公开的共享数据集, 所有用户都可以访问, 省去重复创建数据集的代价 下面的章节将会介绍数据集的几类操作: 创建数据集 使用数据集 共享数据集 "},"03-concepts/3.2-shared-storage.html":{"url":"03-concepts/3.2-shared-storage.html","title":"3.2 共享存储","keywords":"","body":"共享存储 共享存储和后面将要介绍的工作台和训练任务紧密相关. AVA 平台使用的所有数据都来源于云, 并以文件系统协议提供访问. 从存储的使用形式来讲, 有两种共享存储: AVA 本地存储集群的共享存储 AVA 提供了一套内部用的存储集群, 大小在几十 TiB 范围. 一般情况下, 用户可以把经常修改的配置文件, 程序代码放在这个集群内部. 对于每个用户和组, AVA 以工作目录形式提供本地集群的部分空间供用户使用. 这部分存储空间和对象存储不互相共享. 建议把程序, log 和一些中间处理结果放在这里. 云上对象存储共享 AVA 训练数据基本来源于互联网, 大部分数据也存储于互联网, 目前基于对象存储, 可轻松扩展到 PiB 级别. 用户的不同训练任务可以同时以读写方式访问这些数据, 不同用户也可以互相共享这些数据. 根据不同的共享对象和范围, 可以从几个角度来理解共享存储: 用户存储在训练间的共享 对单个用户来说, 他可以访问他自己的所有存储, “共享” 的概念是指该用户启动的所有工作台和训练都能访问自己的数据, 并且是读写共享的. 也就意味着, 在一个训练中生成的文件在该用户其它训练中也可以看到, 包括工作台和训练任务 (下面将介绍). 同时, 用户对数据的改动都将反应到云端. 组用户共享 用户可以根据其关系划分为不同的组. 在 AVA 平台, 同组内的部分数据是可以共享的. 每个组有一个共享目录, 组内每个成员都有一个子目录, 组内所有成员可以访问该组共享目录. 七牛云存储 Bucket 共享 每个用户的对象存储 Bucket 缺省是不共享的, 如果不共享, 则只有该用户可以挂载并查看其中内容 如果用户选择共享 Bucket 给特定用户, 则该用户能看到 Bucket 的数据 数据集的共享 公开共享存储由 AVA 平台提供, 一般是常用的数据集, 并可以以格式化方式提供, 比如 RecordIO. 用户也可以选择把自己的数据集共享. "},"03-concepts/3.3-workspace.html":{"url":"03-concepts/3.3-workspace.html","title":"3.3 工作台","keywords":"","body":"工作台 工作台是用户调试训练代码, 准备训练数据的工作环境. 工作台和训练任务是很相似的, 但是作用不同. 相同点是, 它们都是基于容器工作, 都可以访问 AVA 平台提供的共享存储. 也就是说, 共享存储是连接工作台和训练任务的纽带. 典型工作流是, 在工作台中把算法和数据准备好后, 在训练任务中访问共享存储, 执行训练, 输出结果又可以在工作台中访问. 每个用户都可以启动自己的工作台. 工作台又分为 CPU 工作台和 GPU 工作台. CPU 工作台用于编辑代码和数据, GPU 工作台用于做简单调试, 分配的 GPU 资源会比较少. 如果要启动正式的训练, 请使用训练任务. 由于工作台主要目的是准备代码和数据, 每个用户只能开启一个工作台. 工作台缺省会挂载组内共享存储, 这些存储以 AVA 内部存储集群的方式提供服务. 进入工作台后, 可在 /workspace/mnt/group/[group_name]/[user_name] 目录访问到用户自己的数据, 其中 group_name 是用户所属组的名字, user_name 是用户名. 用户可以访问 group_name 下的所有数据. 工作台可以选择挂载一或多个 Bucket, 目前最多挂载 3 个. 挂载后, 用户可以在 /workspace/mnt/bucket/[bucket_name] 目录下访问 Bucket 中的数据. 其中, bucket_name 是用户选择挂载的 Bucket 名字, 如果挂载多个 Bucket, 在 /workspace/mnt/bucket 下会存在多个子目录. AVA 的工作台基于 JupyterLab 提供交互访问, 用户可以使用终端, 文件编辑器, Jupyter Notebook 编辑和调试训练代码 "},"03-concepts/3.4-training.html":{"url":"03-concepts/3.4-training.html","title":"3.4 训练任务","keywords":"","body":"训练任务 AVA 通过工作台和训练实现算法调试和训练执行的分离. 每个训练任务使用特定的硬件资源, 在特定的运行环境中执行特定的算法逻辑, (可能) 消费特定的数据. 训练任务的执行入口是一个确定会终止的程序. 训练任务的算法逻辑, 训练数据, 执行环境, 硬件资源等在创建时完全确定, 执行中不能修改. 与工作台一样, 训练任务也是容器, 可访问共享存储, 不同的地方在于: 训练一般是计算密集型任务, 通常使用 GPU 运行 用户不能登录进训练容器, 训练的 log 可在工作台查看 训练资源不可长期持有, 训练结束后资源立即释放 一般在工作台中准备训练所需的代码和数据, 代码和少量数据可以存储在组共享空间, 大量数据推荐使用七牛云存储. 启动训练时, 需要指定训练执行入口, 挂载云存储 Bucket, 选择运行环境 (镜像) 和硬件资源. "},"03-concepts/3.5-quota.html":{"url":"03-concepts/3.5-quota.html","title":"3.5 Quota","keywords":"","body":"Quota Quota 用来控制用户和组对资源的使用. 如果没有 Quota, 单个用户可以轻松占有 AVA 集群的所有资源, 其他用户将无资源可用. Quota 控制的对象有 GPU, CPU 和内存. 控制的粒度是组和个人, 并且可由管理员动态调整. 每个组在创建时被分配了固定的 GPU, CPU 和内存 Quota, 在 Quota 未满时, 用户可以创建工作台或者训练任务. 工作台和训练任务需要占有一定的资源, 在工作台和训练任务执行期间, 它们将占用相应资源 Quota. 启动新的工作台和训练时, 如果剩余的 Quota 不足, 则不能启动. 在工作台和训练任务结束后, Quota 将自动归还. 注意, 训练任务结束后, 容器被自动销毁, Quota 自动归还. 工作台不会被自动销毁, 此时, Quota 不会被归还. "},"03-concepts/3.6-image.html":{"url":"03-concepts/3.6-image.html","title":"3.6 镜像","keywords":"","body":"镜像 镜像指运行工作台或训练任务时需要的 Docker 镜像. 每个镜像包含了特定的运行环境. 除了常用的系统软件, AVA的镜像还包含如下的内容： 深度学习训练框架 AVA 平台提供了多种常用机器学习框架镜像, 目前支持 MXNet, Caffe, TensorFlow, PyTorch 等 AVA SDK AVA SDK 是针对具体训练框架开发的, 提供两个主要功能, 一个是提供包装好的深度学习训练入口, 二是收集训练过程各项参数, 这样, 在 AVA 中可以查看训练参数的走势图, 比如 Accuracy, Loss 等. AVA 平台提供了一系列的预定义镜像, 所有用户可直接使用. 这些镜像按照不同训练框架命名, 每个镜像根据不同依赖区分不同的版本. AVA 还支持用户自定义镜像. 如果AVA基础镜像不能满足要求, 用户可以在 AVA 公开镜像基础上, 使用 Docker, 制作自己的镜像. 将自定义镜像上传到七牛云镜像中心, 在启动工作台和训练时, 可以选择自己上传的镜像. "},"03-concepts/3.7-model.html":{"url":"03-concepts/3.7-model.html","title":"3.7 模型","keywords":"","body":"模型 模型是训练的输出. 使用 AVA SDK 可以将模型文件保存至七牛云存储. 深度学习训练往往需要迭代多次才能达到预期的效果. 多数框架支持将训练的中间模型保存为快照文件 (Snapshot), 快照包含当前模型结构和参数等信息, 可以直接用于推理. 例如, 对于图像分类任务, 可以将外部图像输入至生成的模型, 模型根据训练产生的结构和参数对图像类别作出判断, 并输出类别信息. AVA 平台可以对模型进行管理, 利用 SDK 可以将训练中的模型快照上传至七牛云存储, 并且在 AVA 查看和管理模型. "},"04-quick-start.html":{"url":"04-quick-start.html","title":"4 Quick Start","keywords":"","body":"Quick Start 在对 AVA 平台相关基础概念有一定了解后, 本文会带领大家在深度学习平台上使用平台提供的公开镜像和示例训练代码, 以 CIFAR-10 作为训练数据集, 进行一次完整的训练. 创建训练 使用 AVA 平台, 可以训练出满足您需求的模型, 训练完成后, 可以发布出来进行调用 (发布的功能正在紧张开发中). 而训练一个模型, 一般需要以下 3 步: 选择数据集 选择镜像 选择训练资源 下面讲介绍如何使用AVA平台提供的公开数据集 CIFAR-10 和 MXNet 公开镜像来训练一个模型. 在左侧栏点击 \"训练\" 进入到训练模块, 点击 \"新建训练\" 就可以创建一个训练. 输入训练名称 \"cifar10-demo\" 和描述 (可选) \"This is a training demo for CIFAR-10\" 选择数据集 AVA 平台提供了很多公开数据集供用户使用, 在数据集模块的公开数据集 tab 就可以找到数据集名称为 \"cifar10\" 的数据集. CIFAR-10 数据集所包含的内容, 请参考官网. 训练模型的框架比较多, 目前 AVA 平台能支持的训练框架包括 Caffe, MXNet, TensorFlow 和 PyTorch 等. 使用这些框架进行模型训练时, 使用的数据集一般是需要提前生成为特定的格式, 例如, Caffe 需要 LMDB 格式的数据, 而 MXNet 需要 RecordIO 格式的数据, 当然也可以使用原图格式. 所以, 在开始训练之前, 需要把数据集格式化成需要的格式. 在此示例中, 我们将使用平台提供的 MXNet 的公开镜像, 所以这里数据集需要格式化为 RecordIO 的数据. 平台已经把 CIFAR-10 的这 50000 条数据按照比例格式化为 RecordIO 的训练集 (40000条) 和验证集 (10000). 数据格式化成功完成后, 就可以在训练中使用了. 在训练模型时, 我们一般需要为这个训练选择 \"训练集\" 和 \"验证集\" , 训练集和验证集可以分别来自于不同的数据集的格式化数据. 在本示例中, 我们将选择 3.1 中的公开数据集 \"CIFAR-10\" 格式化的 RecordIO 的数据, 如下图选中百分比为80%的这条格式化数据作为训练集: 一般情况, 我们会把一个数据集拆分成 2 部分, 一部分作为训练集, 一部分作为验证集, 所以当您选择 CIFAR-10 的数据集中那条百分比为80%的格式化数据时, 系统会提示您是否要选择同时格式化 20% 的格式化数据作为验证集. 点击 \"确定\" 按钮, 则选中了训练需要的训练集和验证集: 选择镜像 镜像提供用户训练模型的环境, 用户可以自己构建镜像, 也可以使用公开镜像. AVA平台提供了很多公开镜像供用户使用, 在本示例中我们将使用 MXNet 框架的镜像官方代码, 您可以在镜像模块的公开镜像 tab 找到 \"ava-mxnet\" 的镜像, 请选择版本为 \"py27-cuda80-cudnn6\" 的镜像. 此公开镜像自带 AVA SDK 以及用 AVA SDK 编写的示例训练代码, 代码路径为 /workspace/examples/trainings/mxnet/simple/start.sh, 代码中对 CIFAR-10 数据集, 使用 ResNet50 的网络结构进行训练. 点击 \"下一步\" , 进入到选择训练资源 选择训练资源 在训练资源页面, 用户可以选择GPU资源或CPU资源, 在这里可以选择GPU资源, 目前仅提供1张GPU资源. 执行入口填入的是指定执行的主代码文件, 必填, 这里填入的是示例代码的路径: /workspace/examples/trainings/mxnet/simple/start.sh 点击 \"创建\" 按钮, 可以看到这个训练就处于 \"创建中\" , 意味着分配好资源后. 当显示 \"执行中\" , 代表系统开始执行训练. 训练执行过程中, 您可以在平台中查看训练监控, 查看训练日志和训练产生的模型. 查看训练监控 在训练列表中, 找到你刚才创建的训练 \"cifar10-demo\", 然后点击 \"训练监控\". 即可查看这个训练的 accuracy\\loss\\learning rate 曲线图: 查看训练日志 对于正在执行中的训练, 或者已经完成的训练, 用户都可以查看训练的日志. 现在训练的日志是存储在组共享存储空间的 \"/workspace/mnt/group/qiniu-group-1/avatest/run/train_cifar10-demo_out.log\" 文件中, 查看训练日志, 需要创建一个工作台, 登录到工作台的 Terminal 中, 然后通过 Terminal 进入到组共享存储空间去查看日志纪录. 工作台的详细功能, 请查阅工作台管理. 训练产生的模型 对于训练产生的模型, 可以在AVA平台的模型模块 -> 训练产生模型 tab 进行查看. 找到上面创建的训练 \"cifar10-demo\", 点击左边的展开加号, 就可以看到训练中指定保存的训练产生模型. 您可以下载满足您需求的模型. 恭喜您, 至此, 您就在AVA平台上训练出了一个模型. "},"05-tasks/5.1-dataset.html":{"url":"05-tasks/5.1-dataset.html","title":"5.1 数据集管理","keywords":"","body":"数据集管理 通用流程 将需要训练的数据上传到七牛 bucket, 并以相同的前缀开头, 比如上传到 mybucket 下面: mydataset1/xxx.jpg 利用数据集管理的新建数据集“样本数据”方式, 可以将 bucket 里的图片样本, 生成数据集索引文件 (jsonlist), 比如使用前缀: qiniu:///mybucket/mydataset1/ 将生成数据集索引文件导入 LabelX 进行打标. 参考 82 - 03 LabelX 使用手册 利用数据集管理的新建数据集“源数据集列表”方式, 使用 LabelX 导出打标好的 jsonlist 新建训练用数据集. 新建数据集 可以有三种方式来新建一个数据集: 1. 源数据集列表 源数据集列表是一个文本索引文件, 文件中每行为一条 json 数据(结构展开如下), 代表一张样本图片（或视频）, 其中包含图片的 url 和标签等信息. 这样的文本文件又称 jsonlist. 这是最常用的创建训练用数据集的方式. { \"url\": \"qiniu:///bucketname/prefix/filename\", //必填, 仅支持七牛云bucket的图片, 格式可以是图片的http链接和七牛协议. 私有bucket必须使用七牛协议, 格式为qiniu:///bucketname/prefix/filename, 例如qiniu:///newdata/0081.jpg_wh1200.jpg \"type\": \"image\",// 必填, 目前支持 \"image\"/\"video\" \"source_url\":\"http://source_url\", //图片的来源, augment等操作生成的图片, 来源为原图片url, 下载操作的图片, 来源为原url \"ops\":\"augment(param1,param2...)\", //图片上进行的操作, 下载为download()\" \"label\": [ { \"name\":\"face\" \"type\":\"face\" \"version\":\"1\", \"data\":[ { \"bbox\": [[10, 20], [21, 31], [81, 91]], \"bbox_score\": 0.992, \"landmarks\":[ {\"index\": 1, \"pt\": [1,2], \"score\": 0.91}, {\"index\": 2, \"pt\": [1,2], \"score\": 0.91}, {\"index\": 3, \"pt\": [1,2], \"score\": 0.91}, {\"index\": 4, \"pt\": [1,2], \"score\": 0.91}, ... ], \"cluster\": {\"id\": 1, \"score\": 0.3} } ] }, { \"name\":\"general_imagenet\", \"type\":\"detection\", \"version\":\"1\", \"data\": [ { \"bbox\": [[10, 20], [21, 31], [81, 91]], \"class\": \"dog\", \"score\": 0.998 } ] }, { \"name\":\"terror\", \"type\":\"classification\", \"version\":\"1\", \"data\":[ { \"class\": \"march\", \"score\": 0.998 }, ... ] }, { \"name\":\"pulp\", \"type\":\"classification\", \"version\":\"1\", \"data\": [ { \"class\": \"sexy\", \"score\": 0.998 }, ...] }, { \"name\":\"general\", \"type\":\"classification\", \"version\":\"1\", \"data\": [ { \"class\": \"dog\", \"score\": 0.998 }, ...] }, ] } 2. 格式化数据集 格式化数据是指符合 Caffe 或 MXNet 训练框架所需的 LMDB 或 RecordIO 格式的数据.可以直接上传其数据文件和索引文件, 直接用于训练. 3. 样本数据 样本数据方式是将符合 bucket 前缀的所有文件汇集起来组成的数据. 此方式主要用于生成 jsonlist, 导入 LabelX 进行打标. 注意: 汇集的数据是没有标签的, 不能用于训练. 新建并成功完成后可以看到生成的 jsonlist: 以及数据集里根据标签的统计信息: 格式化数据集 新建好的数据集还不能直接用于训练, 还需要格式化这一个步骤. 所谓格式化就是将数据集的图片生成符合 Caffe 或 MXNet 训练框所需的 LMDB 或 RecordIO 格式, 并保存在平台后端存储上. 如果不需要格式化为框架所需格式, 也可以选择原图方式, 直接将原始图片保存在平台后端存储上. 问题类型是分类还是检测取决于数据集的标签类型是 \"type\":\"classification\" 还是 \"type\":\"detection\". 这样, 训练时选择对应格式化数据集, 训练任务启动后就可以在 /mnt/data 下面找到并应用于训练. "},"05-tasks/5.2-workspace.html":{"url":"05-tasks/5.2-workspace.html","title":"5.2 工作台管理","keywords":"","body":"工作台管理 工作台模块是管理 AVA 平台提供的容器, 用户可以通过 JuypterLab 登录到容器, 进行编写代码, 修改训练参数, 查看日志等. 在 AVA 平台中用户可以根据需要启动 GPU 资源的容器（仍在开发中）或者 CPU 资源的容器. 启动一个容器就需要在 AVA 平台中创建一个工作台. 1. 创建工作台 在工作台模块, 点击 “新建工作台”, 可以创建一个 CPU 的容器用来调试代码, 修改训练参数, 或者查看其他训练和工作台的日志信息. 填写工作台名称 创建工作台的步骤与创建训练一样, 也是 3 步, 分别是 选择数据集 如果用户只是想启动一个容器来进行代码编写或者修改训练参数, 那么可以在第 1 步选择数据集中, 点击“跳过这一步>>”, 那么 AVA 平台就会为客户创建一个没有挂载任何数据集的容器； 选择镜像 用户可以选择自己需要的镜像来启动容器进行调试. 选择资源 工作台创建成功后, 可以在工作台列表中查看到这个工作台的状态, 如果启动成功后, 这个工作台的状态就处于“执行中”. 2. JuypterLab 找到你想进入的工作台, 点击上图紫色框出来的 JuypterLab 的图标, 打开 JupyterLab. 使用 JuypterLab 可以编写代码. 使用 JuypterLab 调试训练. 使用 JuypterLab 可以打开 Terminal, 进入到组共享存储目录中, 查看这个训练的 log, 例如: 在工作台中查看训练任务产生的 log (在 /workspace/mnt/group/[group_name]/[user_name]/run 目录下) : 使用 Jupyter Notebook 调试 Python 代码: 编辑 Markdown 文档: 3. 终止工作台 每个工作台的生命周期不能超过 24 小时, 如果超过 24 小时, 平台会自动把这个工作台占用的资源释放. 已经保存在共享存储目录下的文件不会丢失. 当然, 用户也可以在使用完工作台之后, 手动终止工作台, 释放占用的资源. 终止工作台之后, 那么这个工作台对应的容器就被关闭了, 也就不能再通过 JuypterLab 登录到容器中. 4. 启动工作台 对于已经终止的工作台, 如果用户还需要使用, 那么可以点击“启动工作台”的 icon,再次按照这个工作台的配置启动一个容器. 5. 查看工作台详情 对于 AVA 平台中的工作台, 用户可以点击工作台名称, 进入到工作台详情页面去查看工作台的详情信息. 具体包括容器使用的资源, 组共享存储资源目录, Bucket 目录, 以及挂载的数据集等. 如果用户在调试的过程中, 需要更好使用的数据集, 只需先“终止工作台”, 使该工作台变成“完成”状态, 然后在工作台详情中更换数据集. "},"05-tasks/5.3-training.html":{"url":"05-tasks/5.3-training.html","title":"5.3 训练管理","keywords":"","body":"训练管理 启动训练 使用 AVA 平台, 可以训练出满足您需求的模型, 训练完成后, 可以发布出来进行调用 (发布的功能正在紧张开发中). [info] Tips: 单个训练资源占用的最大时间为 72 小时, 运行时间超过 72 小时的训练会被自动停止. 而训练一个模型, 一般需要以下 3 步. 选择数据集 选择镜像 选择训练资源 下面讲介绍如何使用 AVA 平台提供的公开数据集 CIFAR-10 和公开镜像来训练一个模型. 在左侧栏点击 \"训练\" 进入到训练模块, 点击 \"新建训练\" 就可以创建一个训练: 输入训练名称 \"CIFAR-10-demo\" 和描述 (可选) \"This is a training demo for CIFAR-10\": 选择数据集 AVA 平台提供了很多公开数据集供用户使用, 在数据集模块的公开数据集 tab 就可以找到数据集名称为 \"cifar10\" 的数据集. CIFAR-10 数据集所包含的内容, 请参考官网. 训练模型的框架比较多, 目前 AVA 平台能支持的训练框架包括 Caffe 和 MXNet. 使用这些框架进行模型训练时, 使用的数据集一般是需要提前生成为特定的格式, 例如, Caffe 需要 LMDB 格式的数据, 而 MXNet 需要 RecordIO 格式的数据, 当然也可以使用原图格式. 所以, 在开始训练之前, 需要把数据集格式化成需要的格式. 在此示例中, 我们将使用平台提供的 MXNet 的公开镜像, 所以这里数据集需要格式化为 RecordIO 的数据. 平台已经把 CIFAR-10 的这 50000 条数据按照比例格式化为 RecordIO 的训练集 (40000 条) 和验证集 (10000). 数据格式化成功完成后, 就可以在训练中使用了. 在训练模型时, 我们一般需要为这个训练选择 \"训练集\" 和 \"验证集\", 训练集和验证集可以分别来自于不同的数据集的格式化数据. 在本示例中, 我们将选择 3.1 中的公开数据集 \"CIFAR-10\" 格式化的 RecordIO 的数据, 如下图选中百分比为 80% 的这条格式化数据作为训练集: 一般情况, 我们会把一个数据集拆分成 2 部分, 一部分作为训练集, 一部分作为验证集, 所以当您选择 CIFAR-10 的数据集中那条百分比为 80% 的格式化数据时, 系统会提示您是否要选择同时格式化 20% 的格式化数据作为验证集. 点击 \"确定\" 按钮, 则选中了训练需要的训练集和验证集: 选择镜像 镜像一般包含训练的代码, 以及 AVA 平台需要的一些 SDK 的代码, 用户可以自己构建镜像, 也可以使用公开镜像. AVA 平台提供了很多公开镜像供用户使用, 在本示例中, 对于 CIFAR-10 的数据集, 我们将使用 MXNet 的官方示例 ResNet50 网络训练, 您可以在镜像模块的公开镜像 tab 找到 \"ava-mxnet\" 的镜像, 请选择版本为 \"py27-cuda80-cudnn6\" 的镜像. TODO: 图需更新 点击 \"下一步\" , 进入到选择训练资源 选择训练资源 在训练资源页面, 用户可以选择 GPU 资源或 CPU 资源, 在这里可以选择 GPU 资源, 目前仅提供 1 张 GPU 资源. 执行入口填入的是指定执行的主代码文件, 必填, 这里填入的是 /workspace/examples/trainings/MXNet/simple/start.sh 点击 \"创建\" 按钮, 可以看到这个训练就处于 \"创建中\" , 分配好资源后, 就可以执行训练了. 训练执行过程中, 您可以在平台中查看训练监控, 查看训练日志和训练产生的模型. 查看训练监控 在训练列表中, 找到你刚才创建的训练 \"cifar10-demo\" ,然后点击 \"训练监控\" . 即可查看这个训练的 accuracy\\loss\\learning rate 曲线图. 查看训练日志 对于正在执行中的训练, 或者已经完成的训练, 用户都可以查看训练的日志. 现在训练的日志是存储在组共享存储空间的文件/workspace/mnt/group/qiniu-group-1/avatest/run/train_cifar10-demo_out.log 中. 查看训练日志, 需要创建一个工作台, 启动工作台中的 Terminal, 然后通过 terminal 进入到组共享存储空间去查看日志纪录. 工作台的详细功能, 请查询工作台管理. 停止训练 对于正在执行中的训练, 如果用户想要终止训练, 那么可以通过点击 \"终止训练\" 的按钮来终止这个训练. 训练终止后, 这个训练占用的实例资源会被释放, 正在运行的训练会停止, 保存在组共享存储资源上的数据不会丢失. 重启训练 对于已经完成或者提前终止的训练, 如果用户想要重启这个训练, 则可以点击 \"启动训练\" 的按钮再次启动这个训练. "},"05-tasks/5.4-snapshot-to-model.html":{"url":"05-tasks/5.4-snapshot-to-model.html","title":"5.4 模型管理","keywords":"","body":"模型管理 AVA 平台提供了管理训练模型的能力. 用户可以查看并使用自定义模型, 训练产生的模型, 和公开模型. 后续的评估过程，可以量化模型在评估数据集上的表现. 也可以使用即将上线的应用发布功能, 将这些模型包装成应用服务, 提供在线分类/检测等功能. 自定义模型 用户可以将七牛云存储中的模型文件添加至自定义模型列表中. 训练产生模型 执行训练时, 可以借助 AVA SDK 将训练中间模型 snapshot 上传至七牛云存储, 这些模型可以在 \"训练产生模型\" 标签页查看, 每次训练可以保存多个 snapshot: 也可以查看当前 snapshot 训练中的指标走势, 如损失率: 要实现自动保存模型 snapshot, 用户只需在执行训练时, 设置对应 SDK 回调函数即可, 例如使用 MXNet 时: import mxnet as mx from ava.train import base as train from common import fit def main(): # 初始化 AVA 平台上的训练实例 train_ins = train.TrainInstance() epoch_end_cb = [ # mxnet default epoch callback mx.callback.do_checkpoint( snapshot_prefix, snapshot_interval_epochs), # ava-sdk 提供的 epoch callback train_ins.get_epoch_end_callback( \"mxnet\", batch_of_epoch=batch_of_epoch, epoch_interval=snapshot_interval_epochs) ] fit.fit(args, sym, data.get_rec_iter, ... epoch_end_callback=epoch_end_cb) 详细引用方式请参阅 AVA SDK 示例 公开模型 AVA 中也可以查看平台提供的公开模型: "},"05-tasks/5.5-custom-image.html":{"url":"05-tasks/5.5-custom-image.html","title":"5.5 镜像管理","keywords":"","body":"镜像管理 AVA 平台使用 Docker 镜像管理不同的运行环境, 对于算法开发主要优势有: 统一管理平台和框架依赖, 保证算法执行环境稳定可靠 保持运行环境一致, 加快算法从开发到部署的节奏 快速试错, 快速迭代, 快速迁移, 快速扩展 AVA 平台依托七牛云镜像中心, 整合常用机器学习框架和软件包, 为用户提供丰富且可靠的基础镜像. 同时, 用户可以以这些镜像为基础, 编译自定义镜像并在 AVA 中使用, 方便统一管理团队开发环境. 在镜像模块, 用户可以查看平台提供的公开镜像. 也可以查看用户自己上传到七牛云镜像中心的镜像. 创建工作台或训练时, 可以使用 AVA 公开镜像, 或自己定制的镜像. AVA 公开基础镜像 AVA 平台维护了一些基础镜像, 安装了 AVA SDK, JupyterLab, 常用软件包, 和常用机器学习框架, 支持 CPU 和 GPU, 可满足日常算法开发需求. 登录七牛云镜像中心可以搜索到 AVA 公开镜像及 tag: Image Python AVA SDK JupyterLab CPU CUDA Framework ava-pure - - - ✓ 8.0/9.0/9.1 - ava-sdk 2.7/3.5 ✓ ✓ ✓ 8.0/9.0/9.1 - ava-mxnet 2.7/3.5 ✓ ✓ ✓ 8.0/9.0/9.1 MXNet ava-caffe 2.7/3.5 ✓ ✓ ✓ 8.0/9.0/9.1 Caffe ava-tensorflow 2.7/3.5 ✓ ✓ ✓ 8.0/9.0/9.1 TensorFlow ava-pytorch 2.7/3.5 ✓ ✓ ✓ 8.0/9.0/9.1 PyTorch AVA 公开镜像都基于 Ubuntu 16.04 编译 AVA 公开镜像 (除 ava-pure) 都安装了 JuypterLab, 只有安装了 JupyterLab 的镜像才能在 AVA 工作台中使用 公开镜像使用 tag 区分上游依赖的版本, 如 ava-mxnet:py27-cuda80-cudnn6 表示镜像中安装了 Python 2.7, CUDA 8.0, CUDNN 6 以及最新版的 MXNet CUDA 版本支持 Nvidia GPU 训练加速 自定义镜像 如果经常需要使用其它暂未支持的框架或软件包, 每次启动 Docker 容器后都需要手动安装, 显然既降低效率, 又提高了维护的难度. 可以根据团队的开发需求, 在公开镜像的基础上安装其它软件包, 构建新的镜像. 例如自定义一个使用 Keras 框架的镜像, 可参考以下步骤. 选择合适的基础镜像 基础镜像中已有的文件和可执行程序在新镜像中也能访问, 因此使用 AVA 公开镜像作为基础, 可以快速构建出需要的新镜像. 我们的新镜像使用 keras 框架配合 tensorflow 后端, 可以在 ava-tensorflow 的基础上安装 keras, 至于 tag 可以先选择 py27-cpu 编译 CPU 版本, 成功后只需替换 tag 即可编译其它平台的 keras. FROM reg.qiniu.com/ava-public/ava-tensorflow:py27-cpu 安装所需软件包 参考 Keras 安装文档, 使用 pip 安装 keras: RUN pip install keras Python 包都使用 PyPI 安装, 避免 Python path 混乱 RUN 后面可以是任意 shell 命令 编译并推送 编译上述镜像并推送至七牛云镜像中心, 即可在 AVA 镜像管理中查看, 并在工作台或训练中使用: 安装 Docker 登录七牛云镜像中心 # 使用七牛云帐号登录 $ docker login reg.qiniu.com -u -p 将上面两行语句写入文件 keras.Dockerfile: FROM reg.qiniu.com/ava-public/ava-tensorflow:py27-cpu RUN pip install keras 编译镜像 ava-keras:py27-cpu. 其中 ava-keras 为镜像名称, py27-cpu 为 tag $ docker build -t ava-keras:py27-cpu -f keras.Dockerfile . 更新镜像 tag, 包含七牛云镜像中心路径 # 将 ava-public 替换为自己的镜像仓库 $ docker tag ava-keras:py27-cpu -t reg.qiniu.com/ava-public/ava-keras:py27-cpu 推送至七牛云镜像中心 $ docker push reg.qiniu.com/ava-public/ava-keras:py27-cpu 参考阅读 Docker 官方文档 七牛云镜像中心 Docker 从入门到实践 "},"05-tasks/5.6-ssh.html":{"url":"05-tasks/5.6-ssh.html","title":"5.6 使用 SSH 登录工作台","keywords":"","body":"使用 SSH 连接工作台 配置 SSH 客户端公钥 用户必须使用已注册的客户端公钥才能登录工作台. 首次使用\b请生成并注册 SSH 客户端密钥. 在自己的电脑上生成 SSH 客户端密钥，在本地Terminal内输入: $ ssh-keygen -t rsa -C \"\" -b 4096 将 替换为自己的邮箱地址, 默认密钥生成在 ~/.ssh/id_rsa, 包含私钥 ~/.ssh/id_rsa 和对应公钥 ~/.ssh/id_rsa.pub. [info] Tips: 请保护好私钥, 公钥可提供给需要连接的服务方. 私钥意外泄露后请立即修改 生成密钥时可以选择启用密码, 每次使用密钥时需输入密码 如果选择将密钥生成在其它目录, 登录时需指定私钥路径, 详见下文 登录 AVA Portal, 在【设置】页面中【新建SSH Key】.将公钥粘贴进去，点击【确定】. 登录工作台 启动工作台后, 查看 SSH 端口, 复制登录命令, 如 ssh root@ -p 在终端执行, 如果不使用默认密钥, 需要指定私钥路径: [info] Tips: 工作台启动的时候会挂载当时已经有的公钥, 之后添加删除都不会影响已经启动的工作台 PyCharm 远程调试 PyCharm 专业版可以通过 SSH 使用服务端的 Python 环境进行远程调试, 避免开发与运行环境不一致, 且可以直接调试 GPU 代码. 请参阅 PyCharm 用户文档配置 远程 Python 解释器并部署本地代码至服务端. [warning] Warning: 当前 PyCharm 远程调试只能进行 Debug, 不能 Run "},"06-tutorial-classification/6.1-dataset-with-jsonlist.html":{"url":"06-tutorial-classification/6.1-dataset-with-jsonlist.html","title":"6.1 准备数据集 (数据集管理方式)","keywords":"","body":"数据准备 下载 cifar10 原始数据 打开 cafiar10 数据的官方页面: https://www.cs.toronto.edu/~kriz/cifar.html, 下载页面中的 CIFAR-10 python version . 下载的文件并解压: $ wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz $ tar zxvf cifar-10-python.tar.gz $ ls cifar-10-batches-py batches.meta data_batch_2 data_batch_4 readme.html data_batch_1 data_batch_3 data_batch_5 test_batch 将原始数据转换为图片 因为文件是经过 python pickle 库序列化的, 所以需要进行反序列化. 序列化格式如下: data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. The first 1024 entries contain the red channel values The next 1024 the green The final 1024 the blue. labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data. 反序列化代码样例如下: #!/usr/bin/python # -*- coding: utf8 -*- import numpy as np import os,io import sys import urllib from glob2 import glob import csv import json import matplotlib.pyplot as plt import matplotlib from matplotlib import image import cPickle from collections import OrderedDict # 有序的词典 def unpickle(file): import cPickle with open(file, 'rb') as fo: dict = cPickle.load(fo) return dict # test_batch test = unpickle('test_batch') data = test['data'] labels = test['labels'] batch_label = test['batch_label'] filenames = test['filenames'] # batches.meta label_names = unpickle('batches.meta')['label_names'] ''' print label_names ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] ''' #将 array 还原为图片 import matplotlib def save_image(data, filenames): for d, f in zip(data, filenames): img = d.reshape(3, 32, 32) img = np.swapaxes(img, 0, 2) img = np.swapaxes(img, 0, 1) assert img.shape == (32,32,3) image.imsave(f, img) 图片上传至七牛 Bucket 首先, 需要下载、安装 qshell, 参考: https://developer.qiniu.com/kodo/tools/1302/qshell 之后, 登陆 portal.qiniu.com, 获取自己账户的 ak/sk $ qshell account $ qshell qupload 4 ./upload.json Writing upload log to file /Users/quxiao/.qshell/qupload/5949acac101b55bd7a79a6c30e67a172/5949acac101b55bd7a79a6c30e67a172.log Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/abandoned_ship_s_000004.png => cifar10-raw-datasetabandoned_ship_s_000004.png [1/50000, 0.0%] ... Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/abandoned_ship_s_000024.png => cifar10-raw-datasetabandoned_ship_s_000024.png [2/50000, 0.0%] ... Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/abandoned_ship_s_000034.png => cifar10-raw-datasetabandoned_ship_s_000034.png [3/50000, 0.0%] ... Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/abandoned_ship_s_000035.png => cifar10-raw-datasetabandoned_ship_s_000035.png [4/50000, 0.0%] ... Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/abandoned_ship_s_000146.png => cifar10-raw-datasetabandoned_ship_s_000146.png [5/50000, 0.0%] .. ... Uploading /Users/quxiao/git_rep/github.com/quxiao/cifar10-example/dataset/data/image/yosemite_toad_s_000172.png => cifar10-raw-dataset/yosemite_toad_s_000172.png [50000/50000, 100.0%] ... See upload log at path /Users/quxiao/.qshell/qupload/5949acac101b55bd7a79a6c30e67a172/5949acac101b55bd7a79a6c30e67a172.log 其中, upload.json 内容为: { \"src_dir\" : \"./data/image/\", # cifar10 图片所在目录 \"bucket\" : \"\", # 账户下的 bucket 名称 \"key_prefix\" : \"cifar10-raw-dataset/\" # 指定的 bucket key 前缀 } 生成数据集 json list AVA 平台数据集 json 格式 对于图片分类问题, 数据集的 json 格式如下: { \"url\": \"qiniu:///bucketname/prefix/filename\", //必填, 仅支持七牛云 Bucket 的图片, 格式可以是图片的http链接和七牛协议. 私有 Bucket 必须使用七牛协议, 格式为qiniu:///bucketname/prefix/filename, 例如qiniu:///newdata/0081.jpg_wh1200.jpg \"type\": \"image\",// 必填, 目前支持 \"image\"/\"video\" \"source_url\":\"http://source_url\", //图片的来源, augment等操作生成的图片, 来源为原图片url, 下载操作的图片, 来源为原url \"label\": [ { \"name\":\"cifar10\", \"type\":\"classification\", \"version\":\"1\", \"data\": [{ \"class\": \"dog\", }, { ... }] }, ] } 解析生成 json list 文件的样例代码如下: # 增加生成图片和 label 的对应文件 def parse_data(data_file, label_file): print 'parsing data_file %s' % (data_file) p = unpickle(data_file) data = p['data'] labels = p['labels'] # label id list filenames = p['filenames'] print 'save images' save_image(data, 'data/image', filenames) # save data_filename labels dict label_names = unpickle(os.path.dirname(data_file) + '/batches.meta')['label_names'] print 'label_names: %s' % label_names with open(label_file, \"a\") as out: for i in range(len(filenames)): fn = filenames[i] label_name = label_names[labels[i]] out.write('%s\\t%s\\n' % (fn, label_name)) print 'done' bucket_domain='' bucket_key_prefix='' def load_labels(label_file): file_label_dict = dict() with open(label_file, 'r') as f: for line in f: fields = line.split('\\t') if len(fields) %s' % (fname, label_name) data_json = { 'url' : 'http://%s/%s%s' % (bucket_domain, bucket_key_prefix, fname), 'source_url' : 'http://%s/%s%s' % (bucket_domain, bucket_key_prefix, fname), 'type' : 'image', \"label\": [{ \"name\":\"cifar10\", \"type\":\"classification\", \"version\":\"1\", \"data\": [{ \"class\": label_name, }], }], } json_list.append(data_json) import io try: to_unicode = unicode except NameError: to_unicode = str with open(jsonlist_file, 'w') as out_f: for data_json in json_list: line = json.dumps(data_json, ensure_ascii=False) + '\\n' out_f.write(to_unicode(line)) 最后, 将生成的数据集 jsonlist 文件上传至 Bucket, 至此, 数据集的 jsonlist 生成完毕. 创建数据集 在 AVA 平台上, 进入 \"数据集\" -> \"新建数据集\" 页面 我们选择本地上传 jsonlist 文件, 填写数据集名称, 之后点击\"确定创建\". 之后, 数据集会进行\"创建中\"状态. 数据集状态变为\"完成\"之后, 可以在详情页中查看统计信息, 看出数据集的分类统计. 格式化数据集 在数据集详情页, 点击 \"格式化\", 训练集设置为 \"70%\", 验证集设置为 \"30%\", 格式化类型设置为 \"recordio\", 以及 \"原图\". 之后, 可以在详情页查看到数据格式化的结果. "},"06-tutorial-classification/6.2-dataset-with-sharing.html":{"url":"06-tutorial-classification/6.2-dataset-with-sharing.html","title":"6.2 准备数据集 (组/Bucket 共享方式)","keywords":"","body":"通过组内共享准备数据集 数据集除了自己从头开始准备以外, 还可以通过同个组内的其他账号共享数据集的方式, 自己获取到该数据集. 以下是使用自己账号分享数据集的例子. 在数据集列表页, 展现的是自己之前创建好的数据集, 点击\"操作 -> 组内共享\", 如下图所示: 选择自己所在的组: 之后, 在 \"组内共享数据集\" 的列表看到该数据集, 组内的其他账号, 在该列表页也可以看到并使用该数据集了. "},"06-tutorial-classification/6.3-start-training.html":{"url":"06-tutorial-classification/6.3-start-training.html","title":"6.3 开始训练","keywords":"","body":"运行训练 CIFAR-10 的数据集准备好之后, 由于 AVA 平台的公开镜像中, 就包含 CIFAR-10 的训练样例代码 (整合了 AVA SDK), 因为我们通过运行公开镜像就可以直接运行训练了. 在工作台进行调试 在进行正式的训练之前, 我们可以在 AVA 平台上创建一个工作台, 用于确认、调试我们的训练代码. 我们在界面上选择 \"工作台 -> 新建工作台\", 之后在第一步选择数据集时, 将我们之前创建好的数据集选上, 如下图所示: 镜像需要选择: reg.qiniu.com/ava-public/ava-mxnet:py27-cpu, 之后我们就能在工作台页面看到我们创建的工作台了. 之后, 我们点击右侧的进入工作台按钮, 进行到 JupyterLab 界面, 选择 Terminal, 我们就可以在终端中进行操作了. 我们运行样例代码: $ cd /workspace/examples/trainings/mxnet/simple/ $ ./start.sh 通过 Terminal 的输出, 我们可以看到训练代码是正常运行的. 创建训练任务 类似之前创建的工作台任务, 我们继续创建训练任务, 选择数据集之后, 选择镜像: reg.qiniu.com/ava-mxnet:py27-cuda80-cudnn6 (注意, 这次是 GPU 版本的镜像) 再选择训练资源 之后在 \"训练代码的执行入口\" 中, 填入: /workspace/examples/trainings/mxnet/simple/start.sh, 创建完之后, 我们就可以在训练列表页中, 看到训练任务了: 查看训练log 训练任务在运行中, 我们无法直接等到到训练任务所在的环境, 不过, 我们可以通过登录到之前创建的工作台, 来查看训练生成的日志. 进入之前的工作台, 然后查看寻运行 log, log 路径为: /workspace/mnt/group/ava1//run/_out.log. 其中, 是你的用户名, 是你创建的训练任务名称. 如下图所示: 查看训练产生的模型 通过 AVA SDK, 训练任务可以自动帮我们把生成的模型上传至 AVA 平台进行管理, 我们可以通过 \"模型 -> 训练产生模型\" 页面, 查看或者下载这些模型, 如下图所示: "},"07-tutorial-OCR/ocr.html":{"url":"07-tutorial-OCR/ocr.html","title":"7 Tutorial: 训练 OCR 模型","keywords":"","body":"训练一个 OCR 模型 在工作台中执行 OCR 训练 工作台有两种类型: CPU 工作台和 GPU 工作台. GPU 工作台一般做调试用, 但也可以运行训练, 方便调试训练代码. 下面我们展示如何用 GPU 工作台运行 OCR 训练. 值得注意的是, 这里在工作台运行训练只是为了让 demo 过程更加清晰, 实际上应该启动训练任务来运行训练. 环境准备 创建AVA工作台 从工作台标签进入, 选择 \"新建工作台\" 输入名称\"ocr_test\" 选择数据集 跳过这一步 选择镜像 我们选择 ava-mxnet:py35-cuda80-cudnn7 镜像 选择计算资源 这里选择使用 GPU, 然后选择 4 核 CPU, 60G 内存 点击 \"创建\", 等待几秒钟, 工作台可创建出来了 下载 MXNet Example 代码 我们采用 MXNet 框架来运行 OCR 训练. MXNet 缺省包含的 OCR 训练例子在 example/ctc 目录中, 我们可以用如下 git 命令 clone MXNet 源代码: $ git clone git@github.com:apache/incubator-mxnet.git $ cd incubator-mxnet $ cp -r example /workspace/mnt/group///. 把 example 目录拷贝的自己的共享目录, 方便运行. 安装依赖 这里, 我们不准备用 WARPCTC, 那样需要从源码重新安装 MXNet (参考这里) 安装 captch: $ pip3 install captcha 好了, 由于 AVA 的镜像已经安装了 CUDA 及相关的依赖, 这里的 OCR 训练只需要安装 captcha 就可以开始训练了. 运行训练 现在进入工作台, 启动一个 Terminal, 进入 example/ctc 目录下面, 可以看到: ​ 其中, myinfer.sh 是完整训练脚本, 后面运行训练的时候会用到, 这里暂时忽略它. 下面演示如何启动训练, 再用推理识别图片中的文字. 准备字体文件 我们使用的是 Ubuntu 16.04 操作系统, 字体文件存放在 /usr/share/font 下面, 我们可以使用任意字体, 拷贝到当前目录, 执行如下命令: $ cp /usr/share/fonts/truetype/dejavu/DejaVuSans.ttf . 准备样本图片 训练出的模型可用于识别图片中的文字. 执行下面命令生成样本图片: $ python3 captcha_generator.py DejaVuSans.ttf sample.jpg 点击 Jupyter Lab 的 Files tab 中可以看到, 生成的 sample 包含字符 8405: 启动训练 由于这个工作台启用了 GPU, 可以采用 GPU 模式训练: $ python3 lstm_ocr_train.py --gpu 2 --num_proc 2 --loss ctc DejaVuSans.ttf 命令中, —gpu 2 指定用两张 GPU 卡训练, —num_proc 2 表示同时启动 2 个线程训练, 一般设置和 GPU 数目一样, —loss ctc 表示采取 ctc loss 模式. 查看训练过程 这次训练会运行 100 个 epoch, 刚开始的时候, accuracy 都是 0: 到20个epoch左右, accuracy 显著提升, 最后可以提升到 0.95 以上: 推理 训练结束后, 当前目录生成很多模型文件, 一般一个 epoch 一个\b文件, 我们采用第 100 个 epoch 生成的模型做推理: \b执行命令: python3 lstm_ocr_infer.py --prefix ocr --epoch 100 sample1.jpg 输出: Digits: [8, 4, 0, 5], 即为验证样本图中的字符. 启动训练任务执行训练 上面演示了如何通过工作台运行一个 OCR 训练, 下面演示如何启动 AVA 训练来完成相同的过程. 两种方式做的事情是一样的, AVA 训练专用于执行上述训练流程. 首先我们创建 shell 脚本 myinfer.sh 用于启动训练: cd /workspace/mnt/group///example/ctc pip3 install captcha pip3 install numpy cp /usr/share/fonts/truetype/dejavu/DejaVuSans.ttf . python3 captcha_generator.py DejaVuSans.ttf sample1.jpg python3 lstm_ocr_train.py --gpu 2 --num_proc 2 --loss ctc DejaVuSans.ttf python3 lstm_ocr_infer.py --prefix ocr --epoch 100 sample1.jpg [info] Tips: 需要把上面的 和 改成你自己的名字, 然后确保系统中存在 DejaVuSan.ttf 字体文件, 或更换其它字体文件 myinfer.sh 文件需要有可执行权限 创建训练与创建工作台流程类似, 不过需要为训练指定一个可执行入口, 这里指定为 /workspace/mnt/group///example/myinfer.sh 启动训练 在工作台中查看训练输出 log $ cd /workspace/mnt/group///example/run $ tail -f train--log 详细步骤可查阅训练管理 "},"08-tutorial-SSD/ssd.html":{"url":"08-tutorial-SSD/ssd.html","title":"8 Tutorial: 训练 SSD 模型","keywords":"","body":"训练图像检测模型 SSD，英文全称 Single Shot Multibox Detector，是用于目标检测的算法。常见的目标检测算法，如 Faster R-CNN ，存在着速度慢的缺点。SSD 不仅提高了速度，而且提高了准确度。本教程会通过训练模型、评估模型并且演示一个实例，为 AVA 深度学习平台使用者提供在 MXNET 框架上，使用 SSD 模型对目标进行检测。 环境准备 创建 AVA 工作台 从工作台标签进入，选择【新建工作台】 输入名称“SSDtest”，点击确认 选择数据集（可以跳过这一步） 选择所需要的镜像 reg.qiniu.com/ava-public/ava-mxnet:py35-cuda80-cudnn7，然后点击下一步 选择计算资源 此处选择 GPU ，然后选择 4 核 60 G 内存 点击创建，等待工作台创建完成 准备 如果你使用的是 mxnet-python API，你可能已经有了 python 模块，如果没有的话，此处我们需要安装：cv2, matplotlib 和 numpy，使用 apt-get 命令： 首先进行 apt-get update 操作： 再进行sudo apt-get install python-opencv python-matplotlib python-numpy 由于我们要使用 MXNET 来运行 SSD 训练，进一步配置： $ git clone [git@github.com](/var/folders/sc/klgj6bt56195l0nyqzhjw5080000gn/T/abnerworks.Typora/52D8EA54-2FF8-4A92-B1C7-B2BFCF391F8D/mailto:git@github.com):apache/incubator-mxnet.git $ cd incubator-mxnet $ cp -r example /workspace/mnt/group///. 把 example 目录拷贝的自己的共享目录, 方便运行。 训练模型 此示例仅适用于在 Pascal VOC 数据集上的训练。首先下载数据集，再将他们解压至 model 文件夹目录下： 得到： 接着下载 Pascal VOC 数据集： $ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar` $ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar` $ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar` 解压： $ tar -xvf VOCtrainval_11-May-2012.tar` $ tar -xvf VOCtrainval_06-Nov-2007.tar` $ tar -xvf VOCtest_06-Nov-2007.tar` 我们要使用 VOC20017 和 VOC2012 里的 trainval 数据集， VOC2007 和 VOC2012 都在 VOCdevkit 文件夹下，然后将 VOCdevkit 和 data / VOCdevkit 两个文件夹链接到一起， 创建训练： bash tools/prepare_pascal.sh 开始训练： 可以看到每个 batch 训练的速度和损失： 默认情况下，此示例使用的 batch-size 为 32，learning_rate 为 0.002. 我们可以根据不同的配置来微调一下其中的参数，例如，如果你用的是四核的 GPU ： python3 train.py --gpus 0,1,2,3 --batch-size 32. 输入 python3 demo.py —help 获得更多帮助 评估训练模型 确保 val.rec 为验证数据集，运行 python3 evaluate.py --gpus 0,1 --batch-size 128 --epoch 2 运行结果如下图。可以看到由于数据数量较少，平均准确率 MAP（Mean Average Precision）较低： 示例 首先下载模型 ssd_resnet50_0712.zip，将其拷贝至你的 model 目录下 解压文件：apt-get install zip 解压后，ls查看文件夹内得到了 ssd_resnet50_512-0000.params 和 ssd_resnet50_512-symbol.json 运行 接着下载测试要用的图片数据集 然后运行示例： 如果出现 No module named ‘_tkinter’ 的错误，说明没有安装 python3-tk 包，进行安装：apt-get install python3-tk 可以看到 demo.py 运行成功后，目录下出现 tmp.png，此处在Python3 notebook 内用代码输出出片结果： 继续运行： Python3 demo.py --epoch 0 --images ./data/demo/dog.jpg --thresh 0.5 Python3 demo.py --cpu --network resnet50 --data-shape 512 结果： 你可以输入 python demo.py —help 获得更多帮助 "}}